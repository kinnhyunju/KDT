{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mecab import MeCab\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 토크나이저 사용용\n",
    "# mec = MeCab()\n",
    "# file_text = []\n",
    "# dict_text = []\n",
    "# with open('./order.txt', encoding='utf-8') as f :\n",
    "#     while True:\n",
    "#         data = f.readline()\n",
    "#         if not data : break\n",
    "#         # print(data)\n",
    "#         data = data.replace(\"'\",\" \")\n",
    "#         result = mec.morphs(data)\n",
    "#         # print(result)\n",
    "#         labels = []\n",
    "#         while len(labels)<len(result):\n",
    "#             labels.append(0)\n",
    "#         # print(labels)\n",
    "#         # print(f'text : {len(result)}, label : {len(labels)}')\n",
    "#         data_dict = {'tokens':result, 'ner_tags':labels}\n",
    "#         dict_text.append(data_dict)\n",
    "#         file_text.append([result, labels])\n",
    "\n",
    "# # # 저장하기\n",
    "# # for n in range(len(file_text)):\n",
    "# #     with open(\"labels_4.json\", \"a\", encoding=\"utf-8\") as file:\n",
    "# #         if n == 0 :\n",
    "# #             file.write(f'''[\n",
    "# # {{\n",
    "# # \"tokens\" : {str(file_text[n][0]).replace(\"'\",'\"')},\n",
    "# # \"ner_tags\" : {file_text[n][1]}\n",
    "# # }},''')\n",
    "\n",
    "# #         elif n == len(file_text)-1:\n",
    "# #             file.write(f'''\n",
    "# # {{\n",
    "# # \"tokens\" : {str(file_text[n][0]).replace(\"'\",'\"')},\n",
    "# # \"ner_tags\" : {file_text[n][1]}\n",
    "# # }}\n",
    "# # ]''')\n",
    "\n",
    "# #         else : \n",
    "# #             file.write(f'''\n",
    "# # {{\n",
    "# # \"tokens\" : {str(file_text[n][0]).replace(\"'\",'\"')},\n",
    "# # \"ner_tags\" : {file_text[n][1]}\n",
    "# # }},''')\n",
    "\n",
    "# # # 저장하기\n",
    "# # with open(\"labels_2.json\", \"w\", encoding=\"utf-8-sig\") as file:\n",
    "# #     json.dump(dict_text, file,ensure_ascii=False, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "    {\n",
    "        \"tokens\": [\n",
    "            \"오프\", \"커피\", \"에서\", \"아메리카노\", \"핫\", \"으로\", \"2\", \"잔\", \"주문\", \"해\", \"주\", \"세요\", \".\"\n",
    "        ],\n",
    "        \"ner_tags\": [\n",
    "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\n",
    "            \"롤\", \"키\", \"에서\", \"치즈\", \"롤\", \"케이크\", \"한\", \"조각\", \"이랑\", \"아메리카노\", \"아이스\", \"로\", \"하나\", \"씩\", \"부탁\", \"드립니다\", \".\"\n",
    "        ],\n",
    "        \"ner_tags\": [\n",
    "            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# JSON 파일에 저장\n",
    "with open('output.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(test, f, ensure_ascii=False, indent=0, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글자씩 나누기\n",
    "file_text = []\n",
    "with open('./order.txt', encoding='utf-8') as f :\n",
    "    while True:\n",
    "        data = f.readline()\n",
    "        if not data : break\n",
    "        # print(data)\n",
    "        data = data.replace(\". \",\"\")\n",
    "        data = data.strip()\n",
    "        data = data.replace(\"'\",\" \")\n",
    "        data = data.replace(\" \",\"\")\n",
    "        result = list(data)\n",
    "        #print(result)\n",
    "        labels = []\n",
    "        while len(labels)<len(result):\n",
    "            labels.append(0)\n",
    "        # print(labels)\n",
    "        # print(f'text : {len(result)}, label : {len(labels)}')\n",
    "        file_text.append([result, labels])\n",
    "\n",
    "# # 저장하기\n",
    "# for n in range(len(file_text)):\n",
    "#     with open(\"syllable_label.json\", \"a\", encoding=\"utf-8\") as file:\n",
    "#         if n == 0 :\n",
    "#             file.write(f'''[\n",
    "#     {{\n",
    "#       \"tokens\" : {str(file_text[n][0]).replace(\"'\",'\"')},\n",
    "#       \"ner_tags\" : {file_text[n][1]}\n",
    "#     }},''')\n",
    "\n",
    "#         elif n == len(file_text)-1:\n",
    "#             file.write(f'''\n",
    "#     {{\n",
    "#       \"tokens\" : {str(file_text[n][0]).replace(\"'\",'\"')},\n",
    "#       \"ner_tags\" : {file_text[n][1]}\n",
    "#     }}\n",
    "# ]''')\n",
    "\n",
    "#         else : \n",
    "#             file.write(f'''\n",
    "#     {{\n",
    "#       \"tokens\" : {str(file_text[n][0]).replace(\"'\",'\"')},\n",
    "#       \"ner_tags\" : {file_text[n][1]}\n",
    "#     }},''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 2, 2, 2, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 2, 2, 2, 2, 2, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"리\", \"스아라\", \"비카\", \"에서\", \"라떼\", \"에\", \"디카페인\", \"옵션\", \"으로\", \"두\", \"잔\", \",\", \"라지\", \"사이즈\", \"로\", \"부탁\", \"드릴게요\"]\n",
    "ner_tags = [1, 2, 2, 0, 3, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0]\n",
    "result_1 = []\n",
    "\n",
    "for n in range(len(tokens)):\n",
    "    if not ner_tags[n]%2 :\n",
    "        label = str(ner_tags[n])*len(tokens[n])\n",
    "    else :\n",
    "        label = str(ner_tags[n])+(str(int(ner_tags[n])+1)*(len(tokens[n])-1))\n",
    "    for l in label:\n",
    "        result_1.append(int(l))\n",
    "\n",
    "print(result_1)\n",
    "print([1, 2, 2, 2, 2, 2, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"오\", \"프\", \"커\", \"피\", \"에\", \"서\", \"아\", \"메\", \"리\", \"카\", \"노\", \"핫\", \"으\", \"로\", \"2\", \"잔\", \"주\", \"문\", \"해\", \"주\", \"세\", \"요\"]\n",
    "ner_tags = [1, 2, 2, 2, 0, 0, 3, 4, 4, 4, 4, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "tokens = [\"리\", \"스\", \"아\", \"라\", \"비\", \"카\", \"에\", \"서\", \"라\", \"떼\", \"에\", \"디\", \"카\", \"페\", \"인\", \"옵\", \"션\", \"으\", \"로\", \"두\", \"잔\", \",\", \"라\", \"지\", \"사\", \"이\", \"즈\", \"로\", \"부\", \"탁\", \"드\", \"릴\", \"게\", \"요\"]\n",
    "ner_tags = [1, 2, 2, 2, 2, 2, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './ner_김현주.json'\n",
    "\n",
    "file_text = []\n",
    "\n",
    "with open(file_path) as file2:\n",
    "    ner_before = json.load(file2)\n",
    "    for e in ner_before:\n",
    "        tokens = e['tokens']\n",
    "        ner_tags = e['ner_tags']\n",
    "        ner_result = []\n",
    "\n",
    "        for n in range(len(tokens)):\n",
    "            if not ner_tags[n]%2 :\n",
    "                label = str(ner_tags[n])*len(tokens[n])\n",
    "            else :\n",
    "                label = str(ner_tags[n])+(str(int(ner_tags[n])+1)*(len(tokens[n])-1))\n",
    "            for l in label:\n",
    "                ner_result.append(int(l))\n",
    "        \n",
    "        token_result = ''.join(tokens)\n",
    "        token_result = list(token_result)\n",
    "\n",
    "        file_text.append([token_result, ner_result])\n",
    "\n",
    "# # 저장하기\n",
    "# for n in range(len(file_text)):\n",
    "#     with open(\"re_label.json\", \"a\", encoding=\"utf-8\") as file:\n",
    "#         if n == 0 :\n",
    "#             file.write(f'''[\n",
    "#     {{\n",
    "#       \"tokens\" : {str(file_text[n][0]).replace(\"'\",'\"')},\n",
    "#       \"ner_tags\" : {file_text[n][1]}\n",
    "#     }},''')\n",
    "\n",
    "#         elif n == len(file_text)-1:\n",
    "#             file.write(f'''\n",
    "#     {{\n",
    "#       \"tokens\" : {str(file_text[n][0]).replace(\"'\",'\"')},\n",
    "#       \"ner_tags\" : {file_text[n][1]}\n",
    "#     }}\n",
    "# ]''')\n",
    "\n",
    "#         else : \n",
    "#             file.write(f'''\n",
    "#     {{\n",
    "#       \"tokens\" : {str(file_text[n][0]).replace(\"'\",'\"')},\n",
    "#       \"ner_tags\" : {file_text[n][1]}\n",
    "#     }},''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('re_label.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for i in range(len(data)):\n",
    "        text = data[i]['tokens']\n",
    "        text = ''.join(text)\n",
    "        with open('learning_sentence_1.txt',mode='a') as f2:\n",
    "            f2.write(text + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
